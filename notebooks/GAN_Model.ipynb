{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sU49HUdckIID",
        "outputId": "a1f8c525-3227-4ee0-b1db-2bc9e7c1332a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'blood-cell-classification' already exists and is not an empty directory.\n",
            "/content/blood-cell-classification/blood-cell-classification\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/ankitsunil530/blood-cell-classification.git\n",
        "# %cd blood-cell-classification"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiGH1t3MkQ8D",
        "outputId": "e2329241-7e82-44eb-985d-df0786a41790"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o77FxEgYMI7U"
      },
      "source": [
        "# **Blood Cell Classification**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1bd6044"
      },
      "source": [
        "## Data loading and preprocessing\n",
        "\n",
        "### Subtask:\n",
        "Load the blood cell dataset and preprocess the images for use with the vision transformer and Performer models. This will involve resizing, normalization, and splitting the data into training, validation, and test sets.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e819139e"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsR2EzXmf28u",
        "outputId": "cbd0618d-e4a9-46ab-bb2b-156f51918d7d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Downloading mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-skinny==3.6.0 (from mlflow)\n",
            "  Downloading mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.6.0 (from mlflow)\n",
            "  Downloading mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Downloading flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.1.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.17.2)\n",
            "Requirement already satisfied: cryptography<47,>=43.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (43.0.3)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Downloading docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Downloading graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting gunicorn<24 (from mlflow)\n",
            "  Downloading gunicorn-23.0.0-py3-none-any.whl.metadata (4.4 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow)\n",
            "  Downloading huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.12/dist-packages (from mlflow) (3.10.0)\n",
            "Requirement already satisfied: numpy<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.2)\n",
            "Requirement already satisfied: pandas<3 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (18.1.0)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.6.1)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.12/dist-packages (from mlflow) (1.16.3)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow) (2.0.44)\n",
            "Requirement already satisfied: cachetools<7,>=5.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.3.1)\n",
            "Requirement already satisfied: cloudpickle<4 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.2)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fastapi<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.118.3)\n",
            "Requirement already satisfied: gitpython<4,>=3.1.9 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (3.1.45)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (8.7.0)\n",
            "Requirement already satisfied: opentelemetry-api<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-proto<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: opentelemetry-sdk<3,>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.37.0)\n",
            "Requirement already satisfied: packaging<26 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (25.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (5.29.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.12.3)\n",
            "Requirement already satisfied: python-dotenv<2,>=0.19.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (1.2.1)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.3)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (2.32.4)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.5.3)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (4.15.0)\n",
            "Requirement already satisfied: uvicorn<1 in /usr/local/lib/python3.12/dist-packages (from mlflow-skinny==3.6.0->mlflow) (0.38.0)\n",
            "Requirement already satisfied: Mako in /usr/local/lib/python3.12/dist-packages (from alembic!=1.10.0,<2->mlflow) (1.3.10)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.12/dist-packages (from cryptography<47,>=43.0.0->mlflow) (2.0.0)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from docker<8,>=4.0.0->mlflow) (2.5.0)\n",
            "Requirement already satisfied: blinker>=1.9.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (1.9.0)\n",
            "Requirement already satisfied: itsdangerous>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (2.2.0)\n",
            "Requirement already satisfied: jinja2>=3.1.2 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.6)\n",
            "Requirement already satisfied: markupsafe>=2.1.1 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.0.3)\n",
            "Requirement already satisfied: werkzeug>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from Flask<4->mlflow) (3.1.3)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Downloading graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in /usr/local/lib/python3.12/dist-packages (from graphene<4->mlflow) (2.9.0.post0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.3.3)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (4.60.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (1.4.9)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (11.3.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.12/dist-packages (from matplotlib<4->mlflow) (3.2.5)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3->mlflow) (2025.2)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (1.5.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow) (3.2.4)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.12/dist-packages (from cffi>=1.12->cryptography<47,>=43.0.0->mlflow) (2.23)\n",
            "Requirement already satisfied: google-auth~=2.0 in /usr/local/lib/python3.12/dist-packages (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (2.43.0)\n",
            "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in /usr/local/lib/python3.12/dist-packages (from fastapi<1->mlflow-skinny==3.6.0->mlflow) (0.48.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (4.0.12)\n",
            "Requirement already satisfied: zipp>=3.20 in /usr/local/lib/python3.12/dist-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.23.0)\n",
            "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /usr/local/lib/python3.12/dist-packages (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow) (0.58b0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.11)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2025.11.12)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.12/dist-packages (from uvicorn<1->mlflow-skinny==3.6.0->mlflow) (0.16.0)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow) (5.0.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.12/dist-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (4.9.1)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in /usr/local/lib/python3.12/dist-packages (from starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (4.11.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow) (1.3.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.12/dist-packages (from pyasn1-modules>=0.2.1->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.6.1)\n",
            "Downloading mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.9/8.9 MB\u001b[0m \u001b[31m87.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m101.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.8/147.8 kB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Downloading graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.9/114.9 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-23.0.0-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.0/85.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading huey-2.5.4-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.8/76.8 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m753.9/753.9 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Installing collected packages: huey, gunicorn, graphql-core, graphql-relay, docker, graphene, Flask-CORS, databricks-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "Successfully installed Flask-CORS-6.0.1 databricks-sdk-0.73.0 docker-7.1.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 gunicorn-23.0.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0\n"
          ]
        }
      ],
      "source": [
        "!pip install mlflow"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'mlflow'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[3], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms, utils\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfunctional\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mF\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmlflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpytorch\u001b[39;00m\n",
            "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'mlflow'"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n",
            "Note: you may need to restart the kernel to use updated packages.\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Sunil Kumar\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Sunil Kumar\\anaconda3\\Lib\\site-packages)\n",
            "WARNING: Ignoring invalid distribution ~illow (c:\\Users\\Sunil Kumar\\anaconda3\\Lib\\site-packages)\n",
            "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "mysql-connector-python 8.2.0 requires protobuf<=4.21.12,>=4.21.1, but you have protobuf 6.33.1 which is incompatible.\n",
            "pyopenssl 23.0.0 requires cryptography<40,>=38.0.0, but you have cryptography 46.0.3 which is incompatible.\n",
            "tensorflow-intel 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 1.24.3 which is incompatible.\n",
            "tensorflow-intel 2.18.0 requires protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3, but you have protobuf 6.33.1 which is incompatible.\n",
            "\n",
            "[notice] A new release of pip is available: 25.2 -> 25.3\n",
            "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting mlflow\n",
            "  Using cached mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-skinny==3.6.0 (from mlflow)\n",
            "  Using cached mlflow_skinny-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting mlflow-tracing==3.6.0 (from mlflow)\n",
            "  Using cached mlflow_tracing-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting Flask-CORS<7 (from mlflow)\n",
            "  Using cached flask_cors-6.0.1-py3-none-any.whl.metadata (5.3 kB)\n",
            "Requirement already satisfied: Flask<4 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (2.2.2)\n",
            "Requirement already satisfied: alembic!=1.10.0,<2 in c:\\users\\sunil kumar\\appdata\\roaming\\python\\python311\\site-packages (from mlflow) (1.14.1)\n",
            "Collecting cryptography<47,>=43.0.0 (from mlflow)\n",
            "  Using cached cryptography-46.0.3-cp311-abi3-win_amd64.whl.metadata (5.7 kB)\n",
            "Collecting docker<8,>=4.0.0 (from mlflow)\n",
            "  Using cached docker-7.1.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting graphene<4 (from mlflow)\n",
            "  Using cached graphene-3.4.3-py2.py3-none-any.whl.metadata (6.9 kB)\n",
            "Collecting huey<3,>=2.5.0 (from mlflow)\n",
            "  Using cached huey-2.5.4-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: matplotlib<4 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (3.7.1)\n",
            "Requirement already satisfied: numpy<3 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (1.24.3)\n",
            "Requirement already satisfied: pandas<3 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (1.5.3)\n",
            "Requirement already satisfied: pyarrow<23,>=4.0.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (11.0.0)\n",
            "Requirement already satisfied: scikit-learn<2 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (1.2.2)\n",
            "Requirement already satisfied: scipy<2 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (1.10.1)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow) (1.4.39)\n",
            "Collecting waitress<4 (from mlflow)\n",
            "  Using cached waitress-3.0.2-py3-none-any.whl.metadata (5.8 kB)\n",
            "Collecting cachetools<7,>=5.0.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading cachetools-6.2.2-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: click<9,>=7.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (8.0.4)\n",
            "Requirement already satisfied: cloudpickle<4 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (2.2.1)\n",
            "Collecting databricks-sdk<1,>=0.20.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached databricks_sdk-0.73.0-py3-none-any.whl.metadata (40 kB)\n",
            "Collecting fastapi<1 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading fastapi-0.123.0-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting gitpython<4,>=3.1.9 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached gitpython-3.1.45-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: importlib_metadata!=4.7.0,<9,>=3.7.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.0)\n",
            "Collecting opentelemetry-api<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached opentelemetry_api-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Collecting opentelemetry-proto<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached opentelemetry_proto-1.38.0-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting opentelemetry-sdk<3,>=1.9.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: packaging<26 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (23.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.12.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (4.21.12)\n",
            "Requirement already satisfied: pydantic<3,>=2.0.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (2.9.2)\n",
            "Collecting python-dotenv<2,>=0.19.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (2.29.0)\n",
            "Collecting sqlparse<1,>=0.4.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading sqlparse-0.5.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.0.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from mlflow-skinny==3.6.0->mlflow) (4.12.2)\n",
            "Collecting uvicorn<1 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached uvicorn-0.38.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: Mako in c:\\users\\sunil kumar\\appdata\\roaming\\python\\python311\\site-packages (from alembic!=1.10.0,<2->mlflow) (1.3.8)\n",
            "Requirement already satisfied: colorama in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from click<9,>=7.0->mlflow-skinny==3.6.0->mlflow) (0.4.6)\n",
            "Collecting cffi>=2.0.0 (from cryptography<47,>=43.0.0->mlflow)\n",
            "  Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl.metadata (2.6 kB)\n",
            "Collecting google-auth~=2.0 (from databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached google_auth-2.43.0-py2.py3-none-any.whl.metadata (6.6 kB)\n",
            "Collecting protobuf<7,>=3.12.0 (from mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
            "Requirement already satisfied: pywin32>=304 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (305.1)\n",
            "Requirement already satisfied: urllib3>=1.26.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from docker<8,>=4.0.0->mlflow) (1.26.20)\n",
            "Collecting starlette<0.51.0,>=0.40.0 (from fastapi<1->mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading starlette-0.50.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting annotated-doc>=0.0.2 (from fastapi<1->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached annotated_doc-0.0.4-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.2.3)\n",
            "Requirement already satisfied: Jinja2>=3.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (3.1.2)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from Flask<4->mlflow) (2.0.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=3.1.9->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.2.8)\n",
            "Collecting rsa<5,>=3.1.4 (from google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached rsa-4.9.1-py3-none-any.whl.metadata (5.6 kB)\n",
            "Collecting graphql-core<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Using cached graphql_core-3.2.7-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting graphql-relay<3.3,>=3.1 (from graphene<4->mlflow)\n",
            "  Using cached graphql_relay-3.2.0-py3-none-any.whl.metadata (12 kB)\n",
            "Requirement already satisfied: python-dateutil<3,>=2.7.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from graphene<4->mlflow) (2.8.2)\n",
            "Requirement already satisfied: zipp>=0.5 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from importlib_metadata!=4.7.0,<9,>=3.7.0->mlflow-skinny==3.6.0->mlflow) (3.11.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (10.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from matplotlib<4->mlflow) (3.0.9)\n",
            "Collecting opentelemetry-semantic-conventions==0.59b0 (from opentelemetry-sdk<3,>=1.9.0->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl.metadata (2.4 kB)\n",
            "Requirement already satisfied: pytz>=2020.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from pandas<3->mlflow) (2022.7)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from pydantic<3,>=2.0.0->mlflow-skinny==3.6.0->mlflow) (2.23.4)\n",
            "Requirement already satisfied: six>=1.5 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from python-dateutil<3,>=2.7.0->graphene<4->mlflow) (1.16.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from requests<3,>=2.17.3->mlflow-skinny==3.6.0->mlflow) (2023.5.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from rsa<5,>=3.1.4->google-auth~=2.0->databricks-sdk<1,>=0.20.0->mlflow-skinny==3.6.0->mlflow) (0.4.8)\n",
            "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from scikit-learn<2->mlflow) (3.6.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from sqlalchemy<3,>=1.4.0->mlflow) (2.0.1)\n",
            "Collecting anyio<5,>=3.6.2 (from starlette<0.51.0,>=0.40.0->fastapi<1->mlflow-skinny==3.6.0->mlflow)\n",
            "  Downloading anyio-4.12.0-py3-none-any.whl.metadata (4.3 kB)\n",
            "Collecting h11>=0.8 (from uvicorn<1->mlflow-skinny==3.6.0->mlflow)\n",
            "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
            "Requirement already satisfied: pycparser in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from cffi>=2.0.0->cryptography<47,>=43.0.0->mlflow) (2.21)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\sunil kumar\\anaconda3\\lib\\site-packages (from Jinja2>=3.0->Flask<4->mlflow) (2.1.1)\n",
            "Using cached mlflow-3.6.0-py3-none-any.whl (8.9 MB)\n",
            "Using cached mlflow_skinny-3.6.0-py3-none-any.whl (2.4 MB)\n",
            "Using cached mlflow_tracing-3.6.0-py3-none-any.whl (1.3 MB)\n",
            "Downloading cachetools-6.2.2-py3-none-any.whl (11 kB)\n",
            "Using cached cryptography-46.0.3-cp311-abi3-win_amd64.whl (3.5 MB)\n",
            "Using cached databricks_sdk-0.73.0-py3-none-any.whl (753 kB)\n",
            "Using cached docker-7.1.0-py3-none-any.whl (147 kB)\n",
            "Downloading fastapi-0.123.0-py3-none-any.whl (110 kB)\n",
            "Using cached flask_cors-6.0.1-py3-none-any.whl (13 kB)\n",
            "Using cached gitpython-3.1.45-py3-none-any.whl (208 kB)\n",
            "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "Using cached google_auth-2.43.0-py2.py3-none-any.whl (223 kB)\n",
            "Using cached graphene-3.4.3-py2.py3-none-any.whl (114 kB)\n",
            "Using cached graphql_core-3.2.7-py3-none-any.whl (207 kB)\n",
            "Using cached graphql_relay-3.2.0-py3-none-any.whl (16 kB)\n",
            "Using cached huey-2.5.4-py3-none-any.whl (76 kB)\n",
            "Using cached opentelemetry_api-1.38.0-py3-none-any.whl (65 kB)\n",
            "Using cached opentelemetry_proto-1.38.0-py3-none-any.whl (72 kB)\n",
            "Using cached opentelemetry_sdk-1.38.0-py3-none-any.whl (132 kB)\n",
            "Using cached opentelemetry_semantic_conventions-0.59b0-py3-none-any.whl (207 kB)\n",
            "Downloading protobuf-6.33.1-cp310-abi3-win_amd64.whl (436 kB)\n",
            "Using cached python_dotenv-1.2.1-py3-none-any.whl (21 kB)\n",
            "Using cached rsa-4.9.1-py3-none-any.whl (34 kB)\n",
            "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Downloading sqlparse-0.5.4-py3-none-any.whl (45 kB)\n",
            "Downloading starlette-0.50.0-py3-none-any.whl (74 kB)\n",
            "Downloading anyio-4.12.0-py3-none-any.whl (113 kB)\n",
            "Using cached uvicorn-0.38.0-py3-none-any.whl (68 kB)\n",
            "Using cached waitress-3.0.2-py3-none-any.whl (56 kB)\n",
            "Using cached annotated_doc-0.0.4-py3-none-any.whl (5.3 kB)\n",
            "Downloading cffi-2.0.0-cp311-cp311-win_amd64.whl (182 kB)\n",
            "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
            "Installing collected packages: huey, waitress, sqlparse, smmap, rsa, python-dotenv, protobuf, h11, graphql-core, cffi, cachetools, anyio, annotated-doc, uvicorn, starlette, opentelemetry-proto, opentelemetry-api, graphql-relay, google-auth, gitdb, docker, cryptography, opentelemetry-semantic-conventions, graphene, gitpython, Flask-CORS, fastapi, databricks-sdk, opentelemetry-sdk, mlflow-tracing, mlflow-skinny, mlflow\n",
            "\n",
            "   ----------------------------------------  0/32 [huey]\n",
            "   ----------------------------------------  0/32 [huey]\n",
            "   - --------------------------------------  1/32 [waitress]\n",
            "   -- -------------------------------------  2/32 [sqlparse]\n",
            "   --- ------------------------------------  3/32 [smmap]\n",
            "   ----- ----------------------------------  4/32 [rsa]\n",
            "   ------ ---------------------------------  5/32 [python-dotenv]\n",
            "  Attempting uninstall: protobuf\n",
            "   ------ ---------------------------------  5/32 [python-dotenv]\n",
            "    Found existing installation: protobuf 4.21.12\n",
            "   ------ ---------------------------------  5/32 [python-dotenv]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "    Uninstalling protobuf-4.21.12:\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "      Successfully uninstalled protobuf-4.21.12\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   ------- --------------------------------  6/32 [protobuf]\n",
            "   -------- -------------------------------  7/32 [h11]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "  Attempting uninstall: cffi\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "    Found existing installation: cffi 1.15.1\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "    Uninstalling cffi-1.15.1:\n",
            "   ---------- -----------------------------  8/32 [graphql-core]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "      Successfully uninstalled cffi-1.15.1\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ----------- ----------------------------  9/32 [cffi]\n",
            "   ------------ --------------------------- 10/32 [cachetools]\n",
            "  Attempting uninstall: anyio\n",
            "   ------------ --------------------------- 10/32 [cachetools]\n",
            "    Found existing installation: anyio 3.5.0\n",
            "   ------------ --------------------------- 10/32 [cachetools]\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "    Uninstalling anyio-3.5.0:\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "      Successfully uninstalled anyio-3.5.0\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "   ------------- -------------------------- 11/32 [anyio]\n",
            "   --------------- ------------------------ 12/32 [annotated-doc]\n",
            "   ---------------- ----------------------- 13/32 [uvicorn]\n",
            "   ---------------- ----------------------- 13/32 [uvicorn]\n",
            "   ---------------- ----------------------- 13/32 [uvicorn]\n",
            "   ----------------- ---------------------- 14/32 [starlette]\n",
            "   ----------------- ---------------------- 14/32 [starlette]\n",
            "   ----------------- ---------------------- 14/32 [starlette]\n",
            "   ------------------ --------------------- 15/32 [opentelemetry-proto]\n",
            "   ------------------ --------------------- 15/32 [opentelemetry-proto]\n",
            "   -------------------- ------------------- 16/32 [opentelemetry-api]\n",
            "   -------------------- ------------------- 16/32 [opentelemetry-api]\n",
            "   --------------------- ------------------ 17/32 [graphql-relay]\n",
            "   ---------------------- ----------------- 18/32 [google-auth]\n",
            "   ---------------------- ----------------- 18/32 [google-auth]\n",
            "   ---------------------- ----------------- 18/32 [google-auth]\n",
            "   ---------------------- ----------------- 18/32 [google-auth]\n",
            "   ---------------------- ----------------- 18/32 [google-auth]\n",
            "   ----------------------- ---------------- 19/32 [gitdb]\n",
            "   ----------------------- ---------------- 19/32 [gitdb]\n",
            "   ------------------------- -------------- 20/32 [docker]\n",
            "   ------------------------- -------------- 20/32 [docker]\n",
            "   ------------------------- -------------- 20/32 [docker]\n",
            "   ------------------------- -------------- 20/32 [docker]\n",
            "  Attempting uninstall: cryptography\n",
            "   ------------------------- -------------- 20/32 [docker]\n",
            "    Found existing installation: cryptography 39.0.1\n",
            "   ------------------------- -------------- 20/32 [docker]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "    Uninstalling cryptography-39.0.1:\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "      Successfully uninstalled cryptography-39.0.1\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   -------------------------- ------------- 21/32 [cryptography]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------- ---------- 22/32 [opentelemetry-semantic-conventions]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ---------------------------- ----------- 23/32 [graphene]\n",
            "   ------------------------------ --------- 24/32 [gitpython]\n",
            "   ------------------------------ --------- 24/32 [gitpython]\n",
            "   ------------------------------ --------- 24/32 [gitpython]\n",
            "   ------------------------------- -------- 25/32 [Flask-CORS]\n",
            "   -------------------------------- ------- 26/32 [fastapi]\n",
            "   -------------------------------- ------- 26/32 [fastapi]\n",
            "   -------------------------------- ------- 26/32 [fastapi]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   --------------------------------- ------ 27/32 [databricks-sdk]\n",
            "   ----------------------------------- ---- 28/32 [opentelemetry-sdk]\n",
            "   ----------------------------------- ---- 28/32 [opentelemetry-sdk]\n",
            "   ----------------------------------- ---- 28/32 [opentelemetry-sdk]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------ --- 29/32 [mlflow-tracing]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   ------------------------------------- -- 30/32 [mlflow-skinny]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   -------------------------------------- - 31/32 [mlflow]\n",
            "   ---------------------------------------- 32/32 [mlflow]\n",
            "\n",
            "Successfully installed Flask-CORS-6.0.1 annotated-doc-0.0.4 anyio-4.12.0 cachetools-6.2.2 cffi-2.0.0 cryptography-46.0.3 databricks-sdk-0.73.0 docker-7.1.0 fastapi-0.123.0 gitdb-4.0.12 gitpython-3.1.45 google-auth-2.43.0 graphene-3.4.3 graphql-core-3.2.7 graphql-relay-3.2.0 h11-0.16.0 huey-2.5.4 mlflow-3.6.0 mlflow-skinny-3.6.0 mlflow-tracing-3.6.0 opentelemetry-api-1.38.0 opentelemetry-proto-1.38.0 opentelemetry-sdk-1.38.0 opentelemetry-semantic-conventions-0.59b0 protobuf-6.33.1 python-dotenv-1.2.1 rsa-4.9.1 smmap-5.0.2 sqlparse-0.5.4 starlette-0.50.0 uvicorn-0.38.0 waitress-3.0.2\n"
          ]
        }
      ],
      "source": [
        "pip install mlflow"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-dSXeU9vQFH"
      },
      "source": [
        "# GAN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "At_YnNyCfS8e",
        "outputId": "72a15673-67ae-43ba-8737-6960b92c91a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Dataset classes: ['EOSINOPHIL', 'LYMPHOCYTE', 'MONOCYTE', 'NEUTROPHIL']\n",
            "Dataset size: 12515\n",
            "Starting training on device: cuda\n",
            "Total steps per epoch: 391\n",
            "Epoch [1/20]  D_loss: 0.5808  G_loss: 49.1429  time: 83.5s\n",
            "Saved sample and checkpoints for epoch 1\n",
            "Epoch [2/20]  D_loss: 0.3438  G_loss: 46.3876  time: 75.5s\n",
            "Epoch [3/20]  D_loss: 0.3303  G_loss: 43.5043  time: 75.7s\n",
            "Epoch [4/20]  D_loss: 1.2128  G_loss: 4.9556  time: 75.3s\n",
            "Epoch [5/20]  D_loss: 1.0734  G_loss: 2.5391  time: 74.6s\n",
            "Saved sample and checkpoints for epoch 5\n",
            "Epoch [6/20]  D_loss: 1.0945  G_loss: 2.2189  time: 76.5s\n",
            "Epoch [7/20]  D_loss: 1.1901  G_loss: 1.9315  time: 74.8s\n",
            "Epoch [8/20]  D_loss: 1.2475  G_loss: 1.6270  time: 75.3s\n",
            "Epoch [9/20]  D_loss: 1.2469  G_loss: 1.6032  time: 75.4s\n",
            "Epoch [10/20]  D_loss: 1.2174  G_loss: 1.6800  time: 74.6s\n",
            "Saved sample and checkpoints for epoch 10\n",
            "Epoch [11/20]  D_loss: 1.2133  G_loss: 1.6880  time: 76.1s\n",
            "Epoch [12/20]  D_loss: 1.2095  G_loss: 1.7421  time: 74.5s\n",
            "Epoch [13/20]  D_loss: 1.1410  G_loss: 1.9204  time: 75.7s\n",
            "Epoch [14/20]  D_loss: 1.0957  G_loss: 2.0996  time: 74.8s\n",
            "Epoch [15/20]  D_loss: 1.0334  G_loss: 2.2713  time: 75.9s\n",
            "Saved sample and checkpoints for epoch 15\n",
            "Epoch [16/20]  D_loss: 1.0514  G_loss: 2.2541  time: 75.5s\n",
            "Epoch [17/20]  D_loss: 0.9977  G_loss: 2.3150  time: 75.9s\n",
            "Epoch [18/20]  D_loss: 0.9577  G_loss: 2.4107  time: 75.9s\n",
            "Epoch [19/20]  D_loss: 0.9434  G_loss: 2.4440  time: 74.9s\n",
            "Epoch [20/20]  D_loss: 0.9031  G_loss: 2.5200  time: 75.7s\n",
            "Saved sample and checkpoints for epoch 20\n",
            "Training finished!\n"
          ]
        }
      ],
      "source": [
        "# train_gan_corrected.py\n",
        "import os\n",
        "import time\n",
        "import glob\n",
        "import random\n",
        "from pathlib import Path\n",
        "from typing import List\n",
        "\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import torchvision.transforms.functional as F\n",
        "\n",
        "import mlflow\n",
        "import mlflow.pytorch\n",
        "\n",
        "# --------------------\n",
        "# CONFIG / HYPERPARAMS (tweak as needed)\n",
        "# --------------------\n",
        "# Set this to the parent \"images\" folder that contains TRAIN, TEST, TEST_SIMPLE\n",
        "DATASET_PATH = r\"/content/drive/MyDrive/Deep Learning Lab/Blood_Cells_Dataset/Blood_Cells_Dataset/dataset2-master/dataset2-master/images\"\n",
        "\n",
        "OUT_DIR = \"gan_outputs\"\n",
        "MODEL_DIR = \"models\"\n",
        "EXPERIMENT = \"Blood-Cell-GAN\"\n",
        "RUN_NAME = \"DCGAN-corrected-run\"\n",
        "\n",
        "IMG_SIZE = 128          # 64 for faster experiments, 128 gives better visuals\n",
        "BATCH_SIZE = 32         # reduce if OOM on GPU\n",
        "Z_DIM = 100\n",
        "NUM_EPOCHS = 20\n",
        "LR = 2e-4\n",
        "BETA1 = 0.5\n",
        "NUM_WORKERS = 2         # use 0 on Windows if you see DataLoader worker issues\n",
        "SAMPLE_EVERY = 5        # save sample & checkpoint every N epochs\n",
        "LOG_BATCH_EVERY = 200   # log batch metrics to MLflow every N batches\n",
        "\n",
        "# Label smoothing\n",
        "REAL_LABEL = 0.9\n",
        "FAKE_LABEL = 0.0\n",
        "\n",
        "# Device\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "torch.backends.cudnn.benchmark = True  # may speed up for fixed-size inputs\n",
        "\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "os.makedirs(MODEL_DIR, exist_ok=True)\n",
        "\n",
        "# --------------------\n",
        "# Custom Dataset: collects images from TRAIN/TEST/TEST_SIMPLE -> class folders\n",
        "# --------------------\n",
        "class CombinedImageDataset(Dataset):\n",
        "    def __init__(self, images_root: str, transform=None):\n",
        "        \"\"\"\n",
        "        images_root should contain folders like TRAIN, TEST, TEST_SIMPLE.\n",
        "        Each of those contains class folders (e.g., NEUTROPHIL, LYMPHOCYTE, ...).\n",
        "        \"\"\"\n",
        "        self.images_root = Path(images_root)\n",
        "        self.transform = transform\n",
        "\n",
        "        # folders to scan\n",
        "        candidates = [\"TRAIN\", \"TEST\", \"TEST_SIMPLE\"]\n",
        "        self.samples: List[Path] = []\n",
        "        self.classes = set()\n",
        "\n",
        "        for c in candidates:\n",
        "            folder = self.images_root / c\n",
        "            if not folder.exists():\n",
        "                continue\n",
        "            for class_dir in folder.iterdir():\n",
        "                if class_dir.is_dir():\n",
        "                    self.classes.add(class_dir.name)\n",
        "                    # collect image paths\n",
        "                    exts = (\"*.jpg\", \"*.jpeg\", \"*.png\", \"*.bmp\")\n",
        "                    for ext in exts:\n",
        "                        self.samples += list(class_dir.glob(ext))\n",
        "\n",
        "        self.samples = [p for p in self.samples if p.is_file()]\n",
        "        self.samples.sort()  # reproducible order\n",
        "        self.classes = sorted(list(self.classes))\n",
        "        self.class_to_idx = {c: i for i, c in enumerate(self.classes)}\n",
        "\n",
        "        # build label mapping by path -> class index\n",
        "        self.labels = []\n",
        "        for p in self.samples:\n",
        "            # find the class folder name by walking up until we hit the class directory\n",
        "            # sample path: .../images/TRAIN/NEUTROPHIL/img.jpg  -> we want 'NEUTROPHIL'\n",
        "            # find parent in path components that matches a class name\n",
        "            cls_name = None\n",
        "            for parent in p.parents:\n",
        "                if parent.name in self.class_to_idx:\n",
        "                    cls_name = parent.name\n",
        "                    break\n",
        "            if cls_name is None:\n",
        "                # fallback: use folder immediate parent\n",
        "                cls_name = p.parent.name\n",
        "            self.labels.append(self.class_to_idx.get(cls_name, 0))\n",
        "\n",
        "        if len(self.samples) == 0:\n",
        "            raise RuntimeError(f\"No images found under {images_root}. Check DATASET_PATH and structure.\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        p = self.samples[idx]\n",
        "        img = Image.open(p).convert(\"RGB\")\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        label = self.labels[idx]\n",
        "        return img, label\n",
        "\n",
        "# --------------------\n",
        "# Transforms & DataLoader\n",
        "# --------------------\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.5]*3, [0.5]*3),  # scale to [-1, 1]\n",
        "])\n",
        "\n",
        "dataset = CombinedImageDataset(DATASET_PATH, transform=transform)\n",
        "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True,\n",
        "                        num_workers=NUM_WORKERS, pin_memory=True, drop_last=True)\n",
        "\n",
        "print(\"Dataset classes:\", dataset.classes)\n",
        "print(\"Dataset size:\", len(dataset))\n",
        "\n",
        "# --------------------\n",
        "# DCGAN Model definitions (Generator & Discriminator)\n",
        "# --------------------\n",
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, ngf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # z -> ngf*16 x 4 x 4\n",
        "            nn.ConvTranspose2d(z_dim, ngf*16, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*16), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf*8 x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf*16, ngf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf*4 x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf*2 x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf x 64 x 64\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf), nn.ReLU(True),\n",
        "\n",
        "            # -> nc x 128 x 128\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc=3, ndf=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*8, ndf*16, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*16), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*16, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1, 1).squeeze(1)\n",
        "\n",
        "# instantiate models\n",
        "netG = Generator(z_dim=Z_DIM).to(DEVICE)\n",
        "netD = Discriminator().to(DEVICE)\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)\n",
        "\n",
        "# --------------------\n",
        "# Loss and optimizers\n",
        "# --------------------\n",
        "criterion = nn.BCELoss()\n",
        "optimizerD = optim.Adam(netD.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
        "optimizerG = optim.Adam(netG.parameters(), lr=LR, betas=(BETA1, 0.999))\n",
        "\n",
        "fixed_noise = torch.randn(64, Z_DIM, 1, 1, device=DEVICE)\n",
        "\n",
        "# --------------------\n",
        "# MLflow experiment\n",
        "# --------------------\n",
        "mlflow.set_experiment(EXPERIMENT)\n",
        "run = mlflow.start_run(run_name=RUN_NAME)\n",
        "mlflow.log_params({\n",
        "    \"img_size\": IMG_SIZE, \"batch_size\": BATCH_SIZE, \"z_dim\": Z_DIM,\n",
        "    \"lr\": LR, \"beta1\": BETA1, \"epochs\": NUM_EPOCHS, \"device\": str(DEVICE)\n",
        "})\n",
        "\n",
        "print(\"Starting training on device:\", DEVICE)\n",
        "print(\"Total steps per epoch:\", len(dataloader))\n",
        "\n",
        "# --------------------\n",
        "# Training loop (improved)\n",
        "# --------------------\n",
        "iters = 0\n",
        "try:\n",
        "    for epoch in range(1, NUM_EPOCHS + 1):\n",
        "        epoch_start = time.time()\n",
        "        running_D_loss = 0.0\n",
        "        running_G_loss = 0.0\n",
        "\n",
        "        for i, (data, _) in enumerate(dataloader):\n",
        "            netD.zero_grad()\n",
        "\n",
        "            # ------------------\n",
        "            # Train D on real\n",
        "            # ------------------\n",
        "            real_images = data.to(DEVICE)\n",
        "            b_size = real_images.size(0)\n",
        "            real_labels = torch.full((b_size,), REAL_LABEL, dtype=torch.float, device=DEVICE)\n",
        "            output_real = netD(real_images)\n",
        "            errD_real = criterion(output_real, real_labels)\n",
        "            errD_real.backward()\n",
        "            D_x = output_real.mean().item()\n",
        "\n",
        "            # ------------------\n",
        "            # Train D on fake\n",
        "            # ------------------\n",
        "            noise = torch.randn(b_size, Z_DIM, 1, 1, device=DEVICE)\n",
        "            fake_images = netG(noise)\n",
        "            fake_labels = torch.full((b_size,), FAKE_LABEL, dtype=torch.float, device=DEVICE)\n",
        "            output_fake = netD(fake_images.detach())\n",
        "            errD_fake = criterion(output_fake, fake_labels)\n",
        "            errD_fake.backward()\n",
        "            D_G_z1 = output_fake.mean().item()\n",
        "\n",
        "            # Update D\n",
        "            optimizerD.step()\n",
        "\n",
        "            # ------------------\n",
        "            # Train G\n",
        "            # ------------------\n",
        "            netG.zero_grad()\n",
        "            # want generator to produce images labeled as real (smoothed)\n",
        "            gen_labels = torch.full((b_size,), REAL_LABEL, dtype=torch.float, device=DEVICE)\n",
        "            output_for_G = netD(fake_images)\n",
        "            errG = criterion(output_for_G, gen_labels)\n",
        "            errG.backward()\n",
        "            D_G_z2 = output_for_G.mean().item()\n",
        "            optimizerG.step()\n",
        "\n",
        "            # accumulate\n",
        "            running_D_loss += (errD_real.item() + errD_fake.item())\n",
        "            running_G_loss += errG.item()\n",
        "\n",
        "            # occasional logging to MLflow to avoid I/O overhead\n",
        "            if iters % LOG_BATCH_EVERY == 0:\n",
        "                mlflow.log_metric(\"D_loss_batch\", (errD_real.item() + errD_fake.item()), step=iters)\n",
        "                mlflow.log_metric(\"G_loss_batch\", errG.item(), step=iters)\n",
        "\n",
        "            iters += 1\n",
        "\n",
        "        avg_D = running_D_loss / len(dataloader)\n",
        "        avg_G = running_G_loss / len(dataloader)\n",
        "        epoch_time = time.time() - epoch_start\n",
        "        print(f\"Epoch [{epoch}/{NUM_EPOCHS}]  D_loss: {avg_D:.4f}  G_loss: {avg_G:.4f}  time: {epoch_time:.1f}s\")\n",
        "\n",
        "        mlflow.log_metric(\"D_loss_epoch\", avg_D, step=epoch)\n",
        "        mlflow.log_metric(\"G_loss_epoch\", avg_G, step=epoch)\n",
        "\n",
        "        # save checkpoints & samples periodically\n",
        "        if epoch % SAMPLE_EVERY == 0 or epoch == 1 or epoch == NUM_EPOCHS:\n",
        "            g_path = os.path.join(MODEL_DIR, f\"netG_epoch{epoch}.pth\")\n",
        "            d_path = os.path.join(MODEL_DIR, f\"netD_epoch{epoch}.pth\")\n",
        "            torch.save(netG.state_dict(), g_path)\n",
        "            torch.save(netD.state_dict(), d_path)\n",
        "            # save as mlflow artifacts (model weights + sample grid)\n",
        "            mlflow.log_artifact(g_path)\n",
        "            mlflow.log_artifact(d_path)\n",
        "\n",
        "            with torch.no_grad():\n",
        "                fake_samples = netG(fixed_noise).detach().cpu()\n",
        "            grid = utils.make_grid(fake_samples, padding=2, normalize=True)\n",
        "            sample_path = os.path.join(OUT_DIR, f\"sample_epoch{epoch}.png\")\n",
        "            utils.save_image(grid, sample_path)\n",
        "            mlflow.log_artifact(sample_path)\n",
        "            print(f\"Saved sample and checkpoints for epoch {epoch}\")\n",
        "\n",
        "    print(\"Training finished!\")\n",
        "\n",
        "except Exception as e:\n",
        "    print(\"Training interrupted with error:\", e)\n",
        "    raise\n",
        "\n",
        "finally:\n",
        "    # make sure run is ended\n",
        "    mlflow.end_run()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'nn' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[2], line 9\u001b[0m\n\u001b[0;32m      6\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mnormal_(m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m1.0\u001b[39m, \u001b[38;5;241m0.02\u001b[39m)\n\u001b[0;32m      7\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mconstant_(m\u001b[38;5;241m.\u001b[39mbias\u001b[38;5;241m.\u001b[39mdata, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mGenerator\u001b[39;00m(nn\u001b[38;5;241m.\u001b[39mModule):\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, z_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m100\u001b[39m, ngf\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, nc\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m):\n\u001b[0;32m     11\u001b[0m         \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n",
            "\u001b[1;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ],
      "source": [
        "def weights_init(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find('Conv') != -1:\n",
        "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find('BatchNorm') != -1:\n",
        "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        nn.init.constant_(m.bias.data, 0)\n",
        "\n",
        "class Generator(nn.Module):\n",
        "    def __init__(self, z_dim=100, ngf=64, nc=3):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            # z -> ngf*16 x 4 x 4\n",
        "            nn.ConvTranspose2d(z_dim, ngf*16, 4, 1, 0, bias=False),\n",
        "            nn.BatchNorm2d(ngf*16), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf*8 x 8 x 8\n",
        "            nn.ConvTranspose2d(ngf*16, ngf*8, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*8), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf*4 x 16 x 16\n",
        "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*4), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf*2 x 32 x 32\n",
        "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf*2), nn.ReLU(True),\n",
        "\n",
        "            # -> ngf x 64 x 64\n",
        "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(ngf), nn.ReLU(True),\n",
        "\n",
        "            # -> nc x 128 x 128\n",
        "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        return self.net(z)\n",
        "\n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, nc=3, ndf=64):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*2), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*4), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*8), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*8, ndf*16, 4, 2, 1, bias=False), nn.BatchNorm2d(ndf*16), nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(ndf*16, 1, 4, 1, 0, bias=False),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x).view(-1, 1).squeeze(1)\n",
        "\n",
        "# instantiate models\n",
        "netG = Generator(z_dim=Z_DIM).to(DEVICE)\n",
        "netD = Discriminator().to(DEVICE)\n",
        "netG.apply(weights_init)\n",
        "netD.apply(weights_init)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Create folder to save models\n",
        "os.makedirs(\"models\", exist_ok=True)\n",
        "\n",
        "# Save Generator and Discriminator weights\n",
        "torch.save(generator.state_dict(), \"models/gan_generator.pth\")\n",
        "torch.save(discriminator.state_dict(), \"models/gan_discriminator.pth\")\n",
        "\n",
        "print(\"✅ GAN models saved successfully!\")\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
