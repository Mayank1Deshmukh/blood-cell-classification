{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blood Cell Detection with WGAN Data Augmentation + YOLOv8\n",
    "Complete pipeline: Download ZIP → Convert to YOLO → Train WGAN → Generate Synthetic Data → Train YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 0: Mount Google Drive and Download Dataset ZIP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "import shutil\n",
    "from glob import glob\n",
    "\n",
    "# Mount Google Drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "# TODO: Update this path to your Drive dataset location\n",
    "# Example: '/content/drive/MyDrive/archive (3).zip' or '/content/drive/MyDrive/blood-cell-dataset.zip'\n",
    "DRIVE_ZIP_PATH = '/content/drive/MyDrive/archive (3).zip'  # CHANGE THIS PATH\n",
    "\n",
    "# Extract ZIP\n",
    "if os.path.exists(DRIVE_ZIP_PATH):\n",
    "    print(f\"✓ Found ZIP at: {DRIVE_ZIP_PATH}\")\n",
    "    !unzip -q '{DRIVE_ZIP_PATH}' -d /content/\n",
    "    print(\"✓ ZIP extracted\")\n",
    "    \n",
    "    # List extracted contents\n",
    "    !ls -la /content/\n",
    "else:\n",
    "    print(f\"✗ ZIP not found at {DRIVE_ZIP_PATH}\")\n",
    "    print(\"Please update DRIVE_ZIP_PATH to your dataset location\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 1: Convert BCCD XML Annotations to YOLO Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "# Classes mapping\n",
    "classes = [\"WBC\", \"RBC\", \"Platelets\"]\n",
    "\n",
    "def convert_bbox(size, box):\n",
    "    \"\"\"Convert VOC bbox to YOLO normalized format\"\"\"\n",
    "    dw = 1./size[0]\n",
    "    dh = 1./size[1]\n",
    "    x = (box[0] + box[1])/2.0\n",
    "    y = (box[2] + box[3])/2.0\n",
    "    w = box[1] - box[0]\n",
    "    h = box[3] - box[2]\n",
    "    x = x*dw\n",
    "    w = w*dw\n",
    "    y = y*dh\n",
    "    h = h*dh\n",
    "    return (x, y, w, h)\n",
    "\n",
    "# Find BCCD directory\n",
    "bccd_dirs = glob('/content/**/BCCD', recursive=True)\n",
    "if bccd_dirs:\n",
    "    in_dir = bccd_dirs[0]\n",
    "else:\n",
    "    in_dir = '/content/BCCD'  # fallback\n",
    "\n",
    "print(f\"Looking for BCCD in: {in_dir}\")\n",
    "\n",
    "xml_dir = os.path.join(in_dir, \"Annotations\")\n",
    "img_dir = os.path.join(in_dir, \"JPEGImages\")\n",
    "label_dir = os.path.join(in_dir, \"labels\")\n",
    "os.makedirs(label_dir, exist_ok=True)\n",
    "\n",
    "if os.path.exists(xml_dir):\n",
    "    image_list = sorted(os.listdir(xml_dir))\n",
    "    \n",
    "    for xml_filename in image_list:\n",
    "        if not xml_filename.endswith('.xml'):\n",
    "            continue\n",
    "        tree = ET.parse(os.path.join(xml_dir, xml_filename))\n",
    "        root = tree.getroot()\n",
    "        size = root.find('size')\n",
    "        w = int(size.find('width').text)\n",
    "        h = int(size.find('height').text)\n",
    "        yolo_lines = []\n",
    "        for obj in root.iter('object'):\n",
    "            cls = obj.find('name').text\n",
    "            if cls not in classes:\n",
    "                continue\n",
    "            cls_id = classes.index(cls)\n",
    "            xmlbox = obj.find('bndbox')\n",
    "            b = (\n",
    "                float(xmlbox.find('xmin').text),\n",
    "                float(xmlbox.find('xmax').text),\n",
    "                float(xmlbox.find('ymin').text),\n",
    "                float(xmlbox.find('ymax').text)\n",
    "            )\n",
    "            bb = convert_bbox((w, h), b)\n",
    "            yolo_lines.append(f\"{cls_id} {' '.join([str(round(a,6)) for a in bb])}\")\n",
    "        img_base = xml_filename.replace(\".xml\",\".jpg\")\n",
    "        with open(os.path.join(label_dir, xml_filename.replace(\".xml\",\".txt\")), \"w\") as f:\n",
    "            f.write('\\n'.join(yolo_lines))\n",
    "    \n",
    "    print(f\"✓ Converted {len(image_list)} XML annotations to YOLO format\")\nelse:\n",
    "    print(f\"✗ Annotations directory not found at {xml_dir}\")\n",
    "    print(\"Check your extracted directory structure\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 2: Organize Data into train/val/test splits for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from glob import glob\n",
    "import random\n",
    "import os\n",
    "\n",
    "# Create YOLO dataset directory structure\n",
    "os.makedirs(\"yolo_dataset/images/train\", exist_ok=True)\n",
    "os.makedirs(\"yolo_dataset/images/val\", exist_ok=True)\n",
    "os.makedirs(\"yolo_dataset/images/test\", exist_ok=True)\n",
    "os.makedirs(\"yolo_dataset/labels/train\", exist_ok=True)\n",
    "os.makedirs(\"yolo_dataset/labels/val\", exist_ok=True)\n",
    "os.makedirs(\"yolo_dataset/labels/test\", exist_ok=True)\n",
    "\n",
    "# Find BCCD JPEGImages directory\n",
    "jpeg_dirs = glob('/content/**/JPEGImages', recursive=True)\n",
    "if jpeg_dirs:\n",
    "    jpeg_dir = jpeg_dirs[0]\n",
    "    labels_dir = os.path.join(os.path.dirname(jpeg_dir), 'labels')\nelse:\n",
    "    print(\"JPEGImages directory not found\")\n",
    "\n",
    "# Get all images\n",
    "all_imgs = sorted(glob(os.path.join(jpeg_dir, \"*.jpg\")))\n",
    "random.seed(42)\n",
    "random.shuffle(all_imgs)\n",
    "\n",
    "# Split: 80% train, 10% val, 10% test\n",
    "n = len(all_imgs)\n",
    "train_imgs = all_imgs[:int(n*0.8)]\n",
    "val_imgs = all_imgs[int(n*0.8):int(n*0.9)]\n",
    "test_imgs = all_imgs[int(n*0.9):]\n",
    "\n",
    "# Copy images and labels\n",
    "for split, split_imgs in zip(['train','val','test'], [train_imgs, val_imgs, test_imgs]):\n",
    "    for img in split_imgs:\n",
    "        img_base = os.path.basename(img)\n",
    "        lbl_base = img_base.replace('.jpg', '.txt')\n",
    "        shutil.copy(img, f\"yolo_dataset/images/{split}/{img_base}\")\n",
    "        lbl_src = os.path.join(labels_dir, lbl_base)\n",
    "        if os.path.exists(lbl_src):\n",
    "            shutil.copy(lbl_src, f\"yolo_dataset/labels/{split}/{lbl_base}\")\n",
    "\n",
    "print(f\"✓ Split dataset:\")\n",
    "print(f\"  Train: {len(train_imgs)} images\")\n",
    "print(f\"  Val:   {len(val_imgs)} images\")\n",
    "print(f\"  Test:  {len(test_imgs)} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 3: Write data.yaml for YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "yaml_content = f\"\"\"path: {os.path.abspath('yolo_dataset')}\n",
    "train: images/train\n",
    "val: images/val\n",
    "test: images/test\n",
    "nc: 3\n",
    "names: ['WBC','RBC','Platelets']\n",
    "\"\"\"\n",
    "\n",
    "with open('yolo_dataset/data.yaml','w') as f:\n",
    "    f.write(yaml_content)\n",
    "\n",
    "print(\"✓ data.yaml created for YOLO training\")\n",
    "print(\"\\ndata.yaml content:\")\n",
    "print(yaml_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 4: Reorganize BCCD Images for WGAN (ImageFolder Format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from glob import glob\n",
    "import xml.etree.ElementTree as ET\n",
    "import os\n",
    "\n",
    "# Create ImageFolder-style directory for GAN\n",
    "gan_data_dir = \"/content/data\"\n",
    "os.makedirs(gan_data_dir, exist_ok=True)\n",
    "\n",
    "# Extract class labels from XML files\n",
    "xml_files = glob('/content/**/Annotations/*.xml', recursive=True)\n",
    "class_names = {\"WBC\": 0, \"RBC\": 1, \"Platelets\": 2}\n",
    "\n",
    "# Create class subdirectories\n",
    "for class_name in class_names.keys():\n",
    "    os.makedirs(os.path.join(gan_data_dir, class_name), exist_ok=True)\n",
    "\n",
    "# For each image, check what classes it contains and copy to appropriate folders\n",
    "for xml_file in xml_files:\n",
    "    tree = ET.parse(xml_file)\n",
    "    root = tree.getroot()\n",
    "    img_name = root.find('filename').text\n",
    "    \n",
    "    # Get all classes in this image\n",
    "    classes_in_image = set()\n",
    "    for obj in root.iter('object'):\n",
    "        cls = obj.find('name').text\n",
    "        if cls in class_names:\n",
    "            classes_in_image.add(cls)\n",
    "    \n",
    "    # Find and copy image to each class folder it contains\n",
    "    jpeg_dirs = glob('/content/**/JPEGImages', recursive=True)\n",
    "    if jpeg_dirs:\n",
    "        src_img = os.path.join(os.path.dirname(jpeg_dirs[0]), 'JPEGImages', img_name)\n",
    "        if os.path.exists(src_img):\n",
    "            for cls in classes_in_image:\n",
    "                dst_img = os.path.join(gan_data_dir, cls, img_name)\n",
    "                if not os.path.exists(dst_img):\n",
    "                    shutil.copy(src_img, dst_img)\n",
    "\n",
    "print(f\"✓ Organized BCCD images into ImageFolder format at {gan_data_dir}\")\n",
    "print(f\"  Classes: {list(class_names.keys())}\")\n",
    "for class_name in class_names.keys():\n",
    "    count = len(glob(os.path.join(gan_data_dir, class_name, \"*.jpg\")))\n",
    "    print(f\"  - {class_name}: {count} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 5: WGAN - Imports and Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets, utils\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# --------------------\n",
    "# Config / Hyperparams\n",
    "# --------------------\n",
    "DATASET_PATH = \"/content/data\"          # from Cell 4\n",
    "OUT_DIR = \"gan_outputs\"\n",
    "MODEL_DIR = \"models\"\n",
    "IMG_SIZE = 128\n",
    "BATCH_SIZE = 32                         # smaller for stability\n",
    "Z_DIM = 100\n",
    "NUM_EPOCHS = 200                        # more epochs for WGAN\n",
    "LR = 5e-5                               # lower LR for WGAN\n",
    "BETA1 = 0.5\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "SAMPLE_EVERY = 10\n",
    "NUM_WORKERS = 2\n",
    "LAMBDA_GP = 10                          # gradient penalty weight\n",
    "\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "os.makedirs(MODEL_DIR, exist_ok=True)\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 6: WGAN - Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Data preparation\n",
    "# --------------------\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.5]*3, [0.5]*3),  # normalized to [-1,1]\n",
    "])\n",
    "\n",
    "dataset = datasets.ImageFolder(root=DATASET_PATH, transform=transform)\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=NUM_WORKERS,\n",
    "    pin_memory=True\n",
    ")\n",
    "\n",
    "print(\"Dataset classes:\", dataset.classes)\n",
    "print(\"Dataset size:\", len(dataset))\n",
    "print(f\"Number of batches: {len(dataloader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 7: WGAN - Models (Generator & Discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# WGAN Models\n",
    "# --------------------\n",
    "\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Conv') != -1:\n",
    "        nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
    "    elif classname.find('BatchNorm') != -1:\n",
    "        nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
    "        nn.init.constant_(m.bias.data, 0)\n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim=100, ngf=64, nc=3):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.ConvTranspose2d(z_dim, ngf*16, 4, 1, 0, bias=False),\n",
    "            nn.BatchNorm2d(ngf*16),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*16, ngf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*8),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*8, ngf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*4),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*4, ngf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf*2),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf*2, ngf, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ngf),\n",
    "            nn.ReLU(True),\n",
    "\n",
    "            nn.ConvTranspose2d(ngf, nc, 4, 2, 1, bias=False),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, z):\n",
    "        return self.net(z)\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \"\"\"WGAN Discriminator (Critic) - NO sigmoid, outputs raw Wasserstein distance\"\"\"\n",
    "    def __init__(self, nc=3, ndf=64):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(nc, ndf, 4, 2, 1, bias=False),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf, ndf*2, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*2),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*2, ndf*4, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*4),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*4, ndf*8, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*8),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            nn.Conv2d(ndf*8, ndf*16, 4, 2, 1, bias=False),\n",
    "            nn.BatchNorm2d(ndf*16),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "\n",
    "            # NO sigmoid - output raw score\n",
    "            nn.Conv2d(ndf*16, 1, 4, 1, 0, bias=False)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x).view(-1)\n",
    "\n",
    "# Instantiate models\n",
    "netG = Generator(Z_DIM).to(DEVICE)\n",
    "netD = Discriminator().to(DEVICE)\n",
    "netG.apply(weights_init)\n",
    "netD.apply(weights_init)\n",
    "\n",
    "# WGAN uses RMSprop instead of Adam\n",
    "optimizerD = optim.RMSprop(netD.parameters(), lr=LR)\n",
    "optimizerG = optim.RMSprop(netG.parameters(), lr=LR)\n",
    "\n",
    "fixed_noise = torch.randn(64, Z_DIM, 1, 1, device=DEVICE)\n",
    "\n",
    "print(\"✓ Generator and Discriminator initialized (WGAN)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 8: WGAN - Gradient Penalty Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Gradient Penalty for WGAN-GP\n",
    "# --------------------\n",
    "\n",
    "def compute_gradient_penalty(discriminator, real_data, fake_data):\n",
    "    \"\"\"Gradient penalty to enforce Lipschitz constraint\"\"\"\n",
    "    batch_size = real_data.size(0)\n",
    "    \n",
    "    # Sample interpolation coefficient\n",
    "    alpha = torch.rand(batch_size, 1, 1, 1, device=DEVICE)\n",
    "    \n",
    "    # Interpolate between real and fake data\n",
    "    interpolates = (alpha * real_data + (1 - alpha) * fake_data).requires_grad_(True)\n",
    "    \n",
    "    # Discriminator output on interpolated data\n",
    "    d_interpolates = discriminator(interpolates)\n",
    "    \n",
    "    # Compute gradients\n",
    "    fake_output = torch.ones(batch_size, device=DEVICE, requires_grad=False)\n",
    "    gradients = torch.autograd.grad(\n",
    "        outputs=d_interpolates,\n",
    "        inputs=interpolates,\n",
    "        grad_outputs=fake_output,\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "        only_inputs=True\n",
    "    )[0]\n",
    "    \n",
    "    # Compute gradient penalty\n",
    "    gradients = gradients.view(batch_size, -1)\n",
    "    gradient_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "    \n",
    "    return gradient_penalty\n",
    "\n",
    "print(\"✓ Gradient penalty function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 9: WGAN - Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# WGAN-GP Training loop\n",
    "# --------------------\n",
    "\n",
    "iters = 0\n",
    "n_critic = 5  # Train discriminator 5x more than generator\n",
    "\n",
    "for epoch in range(1, NUM_EPOCHS + 1):\n",
    "    epoch_start = time.time()\n",
    "    running_D_loss = 0.0\n",
    "    running_G_loss = 0.0\n",
    "    \n",
    "    for i, (data, _) in enumerate(dataloader):\n",
    "        real_data = data.to(DEVICE)\n",
    "        batch_size = real_data.size(0)\n",
    "        \n",
    "        # --------------------\n",
    "        # Train Discriminator (Critic)\n",
    "        # --------------------\n",
    "        for _ in range(n_critic):\n",
    "            netD.zero_grad()\n",
    "            \n",
    "            # Real data\n",
    "            real_output = netD(real_data)\n",
    "            \n",
    "            # Fake data\n",
    "            noise = torch.randn(batch_size, Z_DIM, 1, 1, device=DEVICE)\n",
    "            fake_data = netG(noise)\n",
    "            fake_output = netD(fake_data.detach())\n",
    "            \n",
    "            # Wasserstein distance (critic loss)\n",
    "            d_loss = -torch.mean(real_output) + torch.mean(fake_output)\n",
    "            \n",
    "            # Gradient penalty\n",
    "            gp = compute_gradient_penalty(netD, real_data, fake_data.detach())\n",
    "            d_loss_total = d_loss + LAMBDA_GP * gp\n",
    "            \n",
    "            d_loss_total.backward()\n",
    "            optimizerD.step()\n",
    "            \n",
    "            running_D_loss += d_loss_total.item()\n",
    "        \n",
    "        # --------------------\n",
    "        # Train Generator\n",
    "        # --------------------\n",
    "        netG.zero_grad()\n",
    "        \n",
    "        noise = torch.randn(batch_size, Z_DIM, 1, 1, device=DEVICE)\n",
    "        fake_data = netG(noise)\n",
    "        fake_output = netD(fake_data)\n",
    "        \n",
    "        # Generator loss (fool the discriminator)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        \n",
    "        g_loss.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        running_G_loss += g_loss.item()\n",
    "        iters += 1\n",
    "    \n",
    "    # Epoch stats\n",
    "    avg_D = running_D_loss / (len(dataloader) * n_critic)\n",
    "    avg_G = running_G_loss / len(dataloader)\n",
    "    epoch_time = time.time() - epoch_start\n",
    "    \n",
    "    if epoch % 10 == 0 or epoch == 1:\n",
    "        print(f\"Epoch [{epoch}/{NUM_EPOCHS}]  D_loss: {avg_D:.4f}  G_loss: {avg_G:.4f}  time: {epoch_time:.1f}s\")\n",
    "    \n",
    "    # Save models & samples periodically\n",
    "    if epoch % SAMPLE_EVERY == 0 or epoch == 1:\n",
    "        g_path = os.path.join(MODEL_DIR, f\"netG_epoch{epoch}.pth\")\n",
    "        d_path = os.path.join(MODEL_DIR, f\"netD_epoch{epoch}.pth\")\n",
    "        torch.save(netG.state_dict(), g_path)\n",
    "        torch.save(netD.state_dict(), d_path)\n",
    "        \n",
    "        # Generate sample grid\n",
    "        with torch.no_grad():\n",
    "            fake_samples = netG(fixed_noise).detach().cpu()\n",
    "        grid = utils.make_grid(fake_samples, padding=2, normalize=True)\n",
    "        sample_path = os.path.join(OUT_DIR, f\"sample_epoch{epoch}.png\")\n",
    "        utils.save_image(grid, sample_path)\n",
    "\n",
    "print(\"✓ WGAN Training finished!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 10: Generate Synthetic Images for Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------\n",
    "# Generate synthetic images\n",
    "# --------------------\n",
    "\n",
    "aug_out_dir = \"synthetic_blood_cells\"\n",
    "os.makedirs(aug_out_dir, exist_ok=True)\n",
    "\n",
    "NUM_SYNTHETIC = 1000  # Generate 1000 synthetic images\n",
    "\n",
    "netG.eval()\n",
    "with torch.no_grad():\n",
    "    for i in range(NUM_SYNTHETIC):\n",
    "        z = torch.randn(1, Z_DIM, 1, 1, device=DEVICE)\n",
    "        fake_img = netG(z).detach().cpu()\n",
    "        # Denormalize from [-1,1] to [0,1]\n",
    "        fake_img = (fake_img + 1) / 2\n",
    "        utils.save_image(fake_img, os.path.join(aug_out_dir, f\"synthetic_{i:05d}.png\"))\n",
    "        if (i + 1) % 100 == 0:\n",
    "            print(f\"Generated {i+1}/{NUM_SYNTHETIC} synthetic images\")\n",
    "\n",
    "print(f\"✓ Generated {NUM_SYNTHETIC} synthetic images in '{aug_out_dir}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 11: Add Synthetic Images to YOLO Training Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "from glob import glob\n",
    "import os\n",
    "\n",
    "# Copy synthetic images to YOLO train folder\n",
    "synthetic_imgs = glob(\"synthetic_blood_cells/*.png\")\n",
    "for syn_img in synthetic_imgs:\n",
    "    img_base = os.path.basename(syn_img)\n",
    "    dst_img = os.path.join(\"yolo_dataset/images/train/\", img_base)\n",
    "    shutil.copy(syn_img, dst_img)\n",
    "    \n",
    "    # Create empty label file (synthetic images have no annotations)\n",
    "    lbl_base = img_base.replace('.png', '.txt')\n",
    "    with open(os.path.join(\"yolo_dataset/labels/train/\", lbl_base), 'w') as f:\n",
    "        f.write(\"\")  # Empty - no objects in synthetic images\n",
    "\n",
    "print(f\"✓ Added {len(synthetic_imgs)} synthetic images to YOLO training set\")\n",
    "total_train = len(glob('yolo_dataset/images/train/*.jpg')) + len(glob('yolo_dataset/images/train/*.png'))\n",
    "print(f\"  Total training images: {total_train}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 12: Install YOLOv8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install YOLOv8 package\n",
    "!pip install ultralytics --upgrade -q\n",
    "\n",
    "import ultralytics\n",
    "print(f\"✓ YOLOv8 version: {ultralytics.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 13: Train YOLOv8 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import os\n",
    "\n",
    "# Load pretrained YOLOv8 nano model\n",
    "model = YOLO('yolov8n.pt')\n",
    "\n",
    "# Train on BCCD dataset (with synthetic augmentation)\n",
    "results = model.train(\n",
    "    data='yolo_dataset/data.yaml',\n",
    "    epochs=100,\n",
    "    imgsz=640,\n",
    "    batch=16,\n",
    "    patience=20,\n",
    "    device=0,  # GPU device\n",
    "    project='blood_cell_detection',\n",
    "    name='yolov8n_bccd'\n",
    ")\n",
    "\n",
    "print(\"✓ YOLO training completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 14: Validate YOLO Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run validation\n",
    "metrics = model.val()\n",
    "\n",
    "print(f\"mAP50: {metrics.box.map50:.3f}\")\n",
    "print(f\"mAP50-95: {metrics.box.map:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 15: Test and Visualize Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "import os\n",
    "\n",
    "# Predict on test images\n",
    "test_images = glob.glob('yolo_dataset/images/test/*.jpg')\n",
    "\n",
    "print(f\"Testing on {len(test_images)} images...\\n\")\n",
    "\n",
    "for i, img_path in enumerate(test_images[:5]):  # Show first 5\n",
    "    results = model.predict(img_path, conf=0.5)\n",
    "    results[0].save(filename=f'test_pred_{i}.jpg')\n",
    "    display(Image(filename=f'test_pred_{i}.jpg'))\n",
    "    print(f\"Image {i+1}: {os.path.basename(img_path)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cell 16: Export Model (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export model to ONNX format\n",
    "model.export(format='onnx')\n",
    "\n",
    "print(\"✓ Model exported to ONNX format\")\n",
    "print(\"  Files available in: runs/detect/yolov8n_bccd/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
